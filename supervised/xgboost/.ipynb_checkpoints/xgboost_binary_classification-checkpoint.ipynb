{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, Imputer\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import xgboost as xgb\n",
    "\n",
    "# from imblearn.over_sampling import SMOTE, RandomOverSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "GOAL = ['target']\n",
    "FEATURES = ['CreditScore', 'Geography', 'Age', 'Tenure',\n",
    "            'Balance', 'NumOfProducts', 'HasCrCard',\n",
    "            'IsActiveMember', 'EstimatedSalary'\n",
    "           ]\n",
    "IGNORED_FEATURES = [] # a placeholder for irrelevant features\n",
    "TRAIN_FEATURES = list(set([c for c in FEATURES if c not in IGNORED_FEATURES]))\n",
    "NUMERICAL_FEATURES = ['CreditScore', 'Age', 'Tenure', 'Balance',\n",
    "                      'NumOfProducts', 'HasCrCard', 'IsActiveMember',\n",
    "                      'EstimatedSalary'] # requires imputation\n",
    "CATEGORICAL_FEATURES = ['Geography', 'Gender'] # requires label encoding followed by imputation\n",
    "\n",
    "over_sampling = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_load_data():\n",
    "    print ('load_data - START')\n",
    "    df = pd.read_csv('../../../data/data_binary_classification_train.csv')\n",
    "    print ('load_data - END')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_train_test_split(df):\n",
    "    print ('train_test_split - START')\n",
    "    train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "    print ('train_test_split - END')\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pre_processing(train_df, test_df):\n",
    "    print ('pre_processing - START')  \n",
    "    # Fill NULL with Mean / Median / -1\n",
    "    for f in NUMERICAL_FEATURES:\n",
    "        # Imputation\n",
    "        imp = Imputer(missing_values='NaN', strategy='median',axis=0, copy=False)\n",
    "        train_df[f] = imp.fit_transform(train_df[f].values.reshape(-1,1))\n",
    "        test_df[f] = imp.fit_transform(test_df[f].values.reshape(-1,1))\n",
    "    \n",
    "    # Pre-processing non-numeric values using numeric encoding, followed by imputation of most_frequent value\n",
    "    # Why use numeric encoding over one hot encoding:\n",
    "    # https://medium.com/data-design/visiting-categorical-features-and-encoding-in-decision-trees-53400fa65931\n",
    "    # Encode using .cat.codes or LabelEncoder:\n",
    "    # http://pbpython.com/categorical-encoding.html\n",
    "    for f in CATEGORICAL_FEATURES:\n",
    "        # Numerical Encoding\n",
    "        train_df[f] = train_df[f].astype('category').cat.codes\n",
    "        test_df[f] = test_df[f].astype('category').cat.codes\n",
    "#         lbl = LabelEncoder()\n",
    "#         train_df[f] = lbl.fit_transform(train_df[f].reshape(-1,1))\n",
    "#         test_df[f] = lbl.fit_transform(test_df[f].reshape(-1,1))\n",
    "        # Imputation\n",
    "        imp = Imputer(missing_values='NaN', strategy='most_frequent',axis=0, copy=False)\n",
    "        train_df[f] = imp.fit_transform(train_df[f].values.reshape(-1,1))\n",
    "        test_df[f] = imp.fit_transform(test_df[f].values.reshape(-1,1))\n",
    "    print ('pre_processing - END') \n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_x_y_split(train_df, test_df):\n",
    "    print ('x_y_split - START')\n",
    "    X_train = train_df[TRAIN_FEATURES]\n",
    "    y_train = train_df[GOAL]\n",
    "    X_test = test_df[TRAIN_FEATURES]\n",
    "    y_test = test_df[GOAL]\n",
    "    print ('x_y_split - END')\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_over_sampling(X_train, y_train):\n",
    "    print ('over_sampling - START')\n",
    "#     TODO: Figure how to oversample using SMOTE \n",
    "#     X_train, y_train = SMOTE().fit_sample(X_train, y_train)\n",
    "#     X_train, y_train = RandomOverSampler().fit_sample(X_train, y_train)\n",
    "    print ('over_sampling - END')\n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_grid_search(X_train, y_train):\n",
    "    print ('grid_search - START')\n",
    "    dmatrix = xgb.DMatrix(data=X_train, label=y_train)\n",
    "    gbm_param_grid = {\n",
    "        'learning_rate': [0.1, 0.05],\n",
    "        'max_depth': [3, 4],\n",
    "        'n_estimators': [500, 750],\n",
    "        'subsample': [0.5, 0.75],\n",
    "        'colsample_bytree': [0.5, 0.75]\n",
    "    }\n",
    "    \n",
    "    gbm = xgb.XGBClassifier()\n",
    "    \n",
    "    # Perform grid search\n",
    "    grid = GridSearchCV(estimator=gbm, param_grid=gbm_param_grid,\n",
    "                            scoring='roc_auc', cv=5, verbose=1)\n",
    "    grid.fit(X_train, y_train.values.ravel()) # Using values.ravel() to change to 1D array - https://stackoverflow.com/questions/42928855/gridsearchcv-error-too-many-indices-in-the-array\n",
    "\n",
    "    # Print the best parameters & metric\n",
    "    print(\"Best parameters found: \", grid.best_params_)\n",
    "    print(\"Best AUC found: \", grid.best_score_)\n",
    "    \n",
    "    best_learning_rate = grid.best_params_[\"learning_rate\"]\n",
    "    best_max_depth = grid.best_params_[\"max_depth\"]\n",
    "    best_n_estimators = grid.best_params_[\"n_estimators\"]    \n",
    "    best_sub_sample = grid.best_params_[\"subsample\"]   \n",
    "    best_colsample_bytree = grid.best_params_[\"colsample_bytree\"]  \n",
    "    \n",
    "    print ('grid_search - END')    \n",
    "    return best_learning_rate, best_max_depth, best_n_estimators, best_sub_sample, best_colsample_bytree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cross_validation(X_train, y_train, best_learning_rate, best_max_depth, best_n_estimators, best_sub_sample, best_colsample_bytree):\n",
    "    print ('cross_validation - START')\n",
    "    dmatrix = xgb.DMatrix(data=X_train, label=y_train)\n",
    "    params = {\"objective\":\"binary:logistic\", \n",
    "              \"learning_rate\":best_learning_rate,\n",
    "              \"max_depth\":best_max_depth,\n",
    "              \"n_estimators\":best_n_estimators,\n",
    "              \"subsample\":best_sub_sample,\n",
    "              \"colsample_bytree\":best_colsample_bytree\n",
    "             }\n",
    "    \n",
    "    print(dmatrix)\n",
    "    \n",
    "    cv_results = xgb.cv(dtrain=dmatrix,\n",
    "                        params=params,\n",
    "                        nfold=5,\n",
    "                        stratified=True,\n",
    "                        num_boost_round=10,\n",
    "                        metrics=\"auc\",\n",
    "                        as_pandas=True,\n",
    "                        seed=123)\n",
    "    print(cv_results)\n",
    "    model_evaluation_metric = cv_results[\"test-auc-mean\"].iloc[-1]\n",
    "    print \"cross-validation model accuracy on train dataset: \", model_evaluation_metric\n",
    "    # TODO: Obtain and print auc standard deviation to identify overfitting\n",
    "    print ('cross_validation - END')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_train_model(X_train, y_train, best_learning_rate, best_max_depth, best_n_estimators, best_sub_sample, best_colsample_bytree):\n",
    "    print ('train_model - START')    \n",
    "    model = xgb.XGBClassifier(objective='binary:logistic',\n",
    "                              learning_rate=best_learning_rate,\n",
    "                              max_depth=best_max_depth,\n",
    "                              n_estimators=best_n_estimators,\n",
    "                              subsample=best_sub_sample,\n",
    "                              colsample_bytree=best_colsample_bytree,\n",
    "                              silent=True,\n",
    "                              seed=123\n",
    "                             )\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    print ('train_model - END')   \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_prediction(model, X_test):\n",
    "    print ('run_prediction - START')  \n",
    "    prediction = model.predict(data=X_test)\n",
    "    print ('run_prediction - END')  \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_evaluation_on_test(prediction, y_test):\n",
    "    print ('model_evaluation_on_test - START')\n",
    "    \n",
    "    cm = confusion_matrix(y_test, prediction)\n",
    "    print \"model confusion matrix: \", cm\n",
    "    \n",
    "    prediction = pd.DataFrame(data = prediction, index=y_test.index, columns = ['target'])\n",
    "    model_evaluation_metric = accuracy_score(y_test, prediction)\n",
    "    print \"model accuracy on test dataset: \", model_evaluation_metric\n",
    "\n",
    "    print ('model_evaluation_on_test - END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_save_model(model):\n",
    "    print ('save_model - START')\n",
    "    pickle.dump(model, open(\"trained_models/xgboost_binary_classification\", \"wb\"))\n",
    "    print ('save_model - END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_feature_importance(model):\n",
    "    print ('feature_importance - START') \n",
    "    xgb.plot_importance(booster=model)\n",
    "    plt.title('Feature Importance')\n",
    "    plt.xlabel('Relative Importance')\n",
    "    plt.ylabel('Features')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print ('feature_importance - END')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_data - START\n",
      "load_data - END\n",
      "train_test_split - START\n",
      "train_test_split - END\n",
      "pre_processing - START\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre_processing - END\n",
      "x_y_split - START\n",
      "x_y_split - END\n",
      "grid_search - START\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    }
   ],
   "source": [
    "def xgboost_binary_classification_train():\n",
    "    start_time = time.time()\n",
    "    df = run_load_data()\n",
    "    train_df, test_df = run_train_test_split(df) # Don't have to run this if you given data is already splitted into train & test\n",
    "    train_df, test_df = run_pre_processing(train_df, test_df)\n",
    "    X_train, y_train, X_test, y_test = run_x_y_split(train_df, test_df)\n",
    "    if over_sampling:\n",
    "        X_train, y_train = run_over_sampling(X_train, y_train)\n",
    "    best_learning_rate, best_max_depth, best_n_estimators, best_sub_sample, best_colsample_bytree = run_grid_search(X_train, y_train)\n",
    "# To check accuracy, run either Grid Search or Cross Validation as Cross Validation is already embedded in Grid Search\n",
    "#     run_cross_validation(X_train, y_train, best_learning_rate, best_max_depth, best_n_estimators, best_sub_sample, best_colsample_bytree)\n",
    "    model = run_train_model(X_train, y_train, best_learning_rate, best_max_depth, best_n_estimators, best_sub_sample, best_colsample_bytree)\n",
    "    prediction = run_prediction(model, X_test)\n",
    "    run_model_evaluation_on_test(prediction, y_test)\n",
    "    run_save_model(model)\n",
    "    run_feature_importance(model)\n",
    "    print('elapsed_time (in seconds): ', time.time() - start_time)\n",
    "xgboost_binary_classification_train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting outcome using trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = ['CreditScore', 'Geography', 'Age', 'Tenure',\n",
    "            'Balance', 'NumOfProducts', 'HasCrCard',\n",
    "            'IsActiveMember', 'EstimatedSalary'\n",
    "           ]\n",
    "IGNORED_FEATURES = [] # a placeholder for irrelevant features\n",
    "TRAIN_FEATURES = list(set([c for c in FEATURES if c not in IGNORED_FEATURES]))\n",
    "NUMERICAL_FEATURES = ['CreditScore', 'Age', 'Tenure', 'Balance',\n",
    "                      'NumOfProducts', 'HasCrCard', 'IsActiveMember',\n",
    "                      'EstimatedSalary'] # requires imputation\n",
    "CATEGORICAL_FEATURES = ['Geography', 'Gender'] # requires label encoding followed by imputation\n",
    "\n",
    "over_sampling = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_load_data():\n",
    "    print ('load_data - START')\n",
    "    df = pd.read_csv('../../../data/data_binary_classification_test.csv')\n",
    "    print ('load_data - END')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pre_processing(df):\n",
    "    print ('pre_processing - START')\n",
    "    # Extract uuid\n",
    "    uuid = pd.DataFrame(df.loc[:,'uuid'], columns = ['uuid']) # Extract uuid column\n",
    "    \n",
    "    # Fill NULL with Mean / Median / -1\n",
    "    for f in NUMERICAL_FEATURES:\n",
    "        # Imputation\n",
    "        imp = Imputer(missing_values='NaN', strategy='median',axis=0, copy=False)\n",
    "        df[f] = imp.fit_transform(df[f].values.reshape(-1,1))\n",
    "    \n",
    "    # Pre-processing non-numeric values using numeric encoding, followed by imputation of most_frequent value\n",
    "    # Why use numeric encoding over one hot encoding:\n",
    "    # https://medium.com/data-design/visiting-categorical-features-and-encoding-in-decision-trees-53400fa65931\n",
    "    # Encode using .cat.codes or LabelEncoder:\n",
    "    # http://pbpython.com/categorical-encoding.html\n",
    "    for f in CATEGORICAL_FEATURES:\n",
    "        # Numerical Encoding\n",
    "        df[f] = df[f].astype('category').cat.codes\n",
    "#         lbl = LabelEncoder()\n",
    "#         train_df[f] = lbl.fit_transform(train_df[f].reshape(-1,1))\n",
    "#         test_df[f] = lbl.fit_transform(test_df[f].reshape(-1,1))\n",
    "        # Imputation\n",
    "        imp = Imputer(missing_values='NaN', strategy='most_frequent',axis=0, copy=False)\n",
    "        df[f] = imp.fit_transform(df[f].values.reshape(-1,1))\n",
    "    print ('pre_processing - END') \n",
    "    return df, uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_x_split(df):\n",
    "    print ('x_split - START')  \n",
    "    X = df[TRAIN_FEATURES]\n",
    "    print ('x_split - END')  \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_load_model():\n",
    "    print ('load_model - START')  \n",
    "    model = pickle.load(open(\"trained_models/xgboost_binary_classification\", \"rb\"))    \n",
    "    print ('load_model - END')  \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_prediction(model, X):\n",
    "    print ('run_prediction - START')  \n",
    "    prediction = model.predict(data=X)\n",
    "    prediction = pd.DataFrame(prediction, columns=['prediction'])\n",
    "    print ('run_prediction - END')  \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_save_prediction(uuid, prediction):\n",
    "    print ('save_prediction - START')\n",
    "    prediction = pd.concat([uuid, prediction], axis=1)\n",
    "    prediction.to_csv('output/prediction_xgboost_binary_classification.csv', sep=',', index=False)\n",
    "    print ('save_prediction - END') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgboost_binary_classification_test():\n",
    "    start_time = time.time()\n",
    "    df = run_load_data()\n",
    "    df, uuid = run_pre_processing(df)\n",
    "    X = run_x_split(df)\n",
    "    model = run_load_model()\n",
    "    prediction = run_prediction(model, X)\n",
    "    run_save_prediction(uuid, prediction)\n",
    "    print('elapsed_time (in seconds): ', time.time() - start_time)\n",
    "xgboost_binary_classification_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
